{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if GPU is available and if torch is using it ..\n",
      "\n",
      "\n",
      "Torch Cuda is available?\n",
      "True\n",
      "Torch Cuda device count is :\n",
      "1\n",
      "Torch Cuda current device is :\n",
      "0\n",
      "Torch Cuda device is :\n",
      "<torch.cuda.device object at 0x0000018F1995ECA0>\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "Pytorch version：\n",
      "1.13.0\n",
      "CUDA Version: \n",
      "11.6\n",
      "cuDNN version is :\n",
      "8302\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Packages import\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "from src.cuda_checker import cuda_torch_check, memory_checker\n",
    "\n",
    "### My modules import\n",
    "from src.data_loader import argObj, data_loaders_stimuli_fmri\n",
    "from src import image_preprocessing\n",
    "from src.feature_extraction import model_loader, fit_pca, pca_batch_calculator, extract_and_pca_features, extract_features_no_pca\n",
    "from src.encoding import linear_regression, compute_perason_numpy\n",
    "from src.evaluation_metrics import median_squared_noisenorm_correlation\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import pearsonr\n",
    "from src.visualize import histogram, box_plot\n",
    "\n",
    "### Cuda setup and check\n",
    "import torch\n",
    "# Select the device to run the model on\n",
    "device = 'cuda' #@param ['cpu', 'cuda'] {allow-input: true}\n",
    "# Check if cuda is available\n",
    "device = torch.device(device)\n",
    "cuda_torch_check()\n",
    "\n",
    "### Parameters definition\n",
    "train_percentage = 90 # X% of the training data will be used for training, (100-X)% for validation\n",
    "transform = image_preprocessing.imagenet_transform_alt\n",
    "\n",
    "batch_size = 64\n",
    "pca_component = 300\n",
    "min_pca_batch_size = pca_component + 200 # pca_component * 2\n",
    "\n",
    "compute_pca = True\n",
    "feature_model_type = \"RetinaNet\" #@param [\"alexnet\", \"vgg16\", \"vgg19_bn, \"\"efficientnetb2\", \"efficientnet_b5\", \"efficientnetb2lib\", \"ZFNet\", \"DINOv2\"]\n",
    "model_layer = \"fpn\"\n",
    "regression_type = \"ridge\" #@param [\"linear\", \"ridge\"]\n",
    "\n",
    "save_predictions = False\n",
    "\n",
    "alpha_l = None\n",
    "alpha_r = None\n",
    "grid_search = False\n",
    "\n",
    "subj = 1\n",
    "noise_norm_corr_dict = {}\n",
    "\n",
    "### Path definition\n",
    "if isinstance(model_layer, list):\n",
    "    model_layer_full = '+'.join(model_layer)\n",
    "else:\n",
    "    model_layer_full = model_layer\n",
    "submission_name = f'{feature_model_type}_{model_layer}-pca_{pca_component}-{regression_type}-alpha_{alpha_l}'\n",
    "\n",
    "# Data folder definition\n",
    "data_dir = '../Datasets/Biomedical/algonauts_2023_challenge_data'\n",
    "# Used to save the prediction of saved model\n",
    "parent_submission_dir = f'./files/submissions/{submission_name}'\n",
    "images_submission_dir = f\"./files/submissions/imgs/{submission_name}\"\n",
    "ncsnr_dir = '../Datasets/Biomedical/algonauts_ncsnr'\n",
    "images_trials_dir = '../Datasets/Biomedical/algonauts_train_images_trials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RetinaNet_fpn-pca_300-ridge-alpha_None'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RetinaNet_fpn-pca_300-ridge-alpha_None\n",
      "\n",
      "############################ Subject: 1 ############################ \n",
      "\n",
      "## Stimulus Images Loading: Info\n",
      "Total train images: 9841\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "Test stimulus images: 159\n",
      "\n",
      "\n",
      "## Loading feature extraction model...\n",
      "\n",
      "\n",
      "Feature extractor: RetinaNet, layer: fpn\n",
      "\n",
      "\n",
      "## Calculating PCA batch size...\n",
      "Batches size: 64\n",
      "Total train instances: 8857\n",
      "PCA components: 300\n",
      "Minimum pca batch size: 500\n",
      "Number of stacked batches for pca: 10\n",
      "PCA batch size (batch_size * n_stacked_batches): 640\n",
      "Last pca batch size: 537\n",
      "## Fitting Incremental PCA (300 components) to training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [25:39<00:00, 11.08s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comulative Explained variance ratio:  0.7038941523115233\n",
      "Number of components:  300\n",
      "## Extracting features from training, validation and test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [03:38<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital features number: 268544, final features number: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:27<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital features number: 268544, final features number: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital features number: 268544, final features number: 300\n"
     ]
    }
   ],
   "source": [
    "print(submission_name + \"\\n\")\n",
    "print('############################ Subject: ' + str(subj) + ' ############################ \\n')\n",
    "# Definining paths to data and submission directories ##\n",
    "args = argObj(subj, data_dir, parent_submission_dir, ncsnr_dir, images_trials_dir, images_submission_dir) \n",
    "# Obtain the indices of the training, validation and test data\n",
    "idxs_train, idxs_val, idxs_test, train_imgs_paths, test_imgs_paths = args.images_idx_splitter(train_percentage)\n",
    "\n",
    "# Defining the images data loaderds\n",
    "data_loaders = data_loaders_stimuli_fmri(idxs_train, \n",
    "                                            idxs_val, \n",
    "                                            idxs_test, \n",
    "                                            train_imgs_paths, \n",
    "                                            test_imgs_paths,\n",
    "                                            lh_fmri_path = args.lh_fmri,\n",
    "                                            rh_fmri_path = args.rh_fmri)\n",
    "\n",
    "train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader = data_loaders.images_dataloader(batch_size, transform)\n",
    "\n",
    "model, feature_extractor = model_loader(feature_model_type, model_layer, device)\n",
    "\n",
    "# Fit the PCA model\n",
    "if compute_pca:\n",
    "    # Fit the PCA model\n",
    "    pca_batch_size, n_stacked_batches = pca_batch_calculator(len(idxs_train),\n",
    "                                                            batch_size,\n",
    "                                                            min_pca_batch_size,\n",
    "                                                            pca_component)\n",
    "    \n",
    "    pca = fit_pca(feature_extractor,\n",
    "                    train_imgs_dataloader,\n",
    "                    pca_component,\n",
    "                    n_stacked_batches,\n",
    "                    pca_batch_size,\n",
    "                    device)\n",
    "    print(\"Comulative Explained variance ratio: \", sum(pca.explained_variance_ratio_))\n",
    "    print(\"Number of components: \", pca.n_components_)\n",
    "    \n",
    "    print('## Extracting features from training, validation and test data...')\n",
    "    features_train = extract_and_pca_features(feature_extractor, train_imgs_dataloader, pca, n_stacked_batches, device)\n",
    "    features_val = extract_and_pca_features(feature_extractor, val_imgs_dataloader, pca, n_stacked_batches, device)\n",
    "    features_test = extract_and_pca_features(feature_extractor, test_imgs_dataloader, pca, n_stacked_batches, device)\n",
    "    \n",
    "    # print(\"\\n\")\n",
    "    # print('## Checking and Freeing  GPU memory...')\n",
    "    # memory_checker()\n",
    "    model.to('cpu') # sposto sulla ram\n",
    "    feature_extractor.to('cpu') # sposto sulla ram\n",
    "    del model, feature_extractor, pca, train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader  # elimino dalla ram\n",
    "    torch.cuda.empty_cache() # elimino la chache vram\n",
    "    gc.collect() # elimino la cache ram\n",
    "    # memory_checker()\n",
    "else:\n",
    "    print('## Extracting features from training, validation and test data...')\n",
    "    features_train = extract_features_no_pca(feature_extractor, train_imgs_dataloader, device)\n",
    "    features_val = extract_features_no_pca(feature_extractor, val_imgs_dataloader, device)\n",
    "    features_test = extract_features_no_pca(feature_extractor, test_imgs_dataloader, device)\n",
    "    \n",
    "    model.to('cpu') # sposto sulla ram\n",
    "    feature_extractor.to('cpu') # sposto sulla ram\n",
    "    del model, feature_extractor, train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader  # elimino dalla ram\n",
    "    torch.cuda.empty_cache() # elimino la chache vram\n",
    "    gc.collect() # elimino la cache ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = data_loaders.fmri_splitter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ## Fit Encoder and Predict...\n",
      "LH fMRI number of vertices: (8857, 19004)\n",
      "RH fMRI number of vertices: (8857, 20544)\n"
     ]
    }
   ],
   "source": [
    "## Fit the linear model ##\n",
    "print('\\n ## Fit Encoder and Predict...')\n",
    "lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = data_loaders.fmri_splitter()\n",
    "print('LH fMRI number of vertices:', lh_fmri_train.shape)\n",
    "print('RH fMRI number of vertices:', rh_fmri_train.shape)\n",
    "# param_grid = {'alpha': [0.0001, 0.0002, 0.001, 0.01, 0.1, 1, 10, 100, 1e3, 5e3, 1e4, 2e4, 5e4, 1e5, 1e6]}\n",
    "\n",
    "param_grid = {'alpha': [1, 10, 100, 1e3, 5e3, 1e4, 2e4, 5e4, 1e5, 2e5, 5e5, 1e6]}\n",
    "#param_grid = {'alpha': [1e6, 2e6, 5e6, 1e7, 2e7, 5e7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Param: {'alpha': 100000.0}\n",
      "Best Score: 0.4171876543623486\n"
     ]
    }
   ],
   "source": [
    "grid_search_l = GridSearchCV(Ridge(), param_grid=param_grid, scoring=make_scorer(\n",
    "    lambda x, y: np.median(compute_perason_numpy(x, y))), cv=5, n_jobs=5, verbose=1)\n",
    "grid_search_l.fit(X=features_train, y=lh_fmri_train)\n",
    "print(\"Best Param: {}\".format(grid_search_l.best_params_))\n",
    "print(\"Best Score: {}\".format(grid_search_l.best_score_))\n",
    "alpha_l = grid_search_l.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_r = alpha_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000.0\n"
     ]
    }
   ],
   "source": [
    "print(alpha_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "grid_search_r = GridSearchCV(Ridge(), param_grid=param_grid, scoring=make_scorer(\n",
    "    lambda x, y: np.median(compute_perason_numpy(x, y))), cv=5, n_jobs=5, verbose=1)\n",
    "grid_search_r.fit(X=features_train, y=rh_fmri_train)\n",
    "print(\"Best Param: {}\".format(grid_search_r.best_params_))\n",
    "print(\"Best Score: {}\".format(grid_search_r.best_score_))\n",
    "alpha_r = grid_search_r.best_params_['alpha']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ridge regressions on the training data...\n",
      "Predicting fMRI data on the validation and test data...\n",
      "Computing the correlation between the predicted and actual fMRI data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:01<00:00, 9556.57it/s] \n",
      "100%|██████████| 20544/20544 [00:01<00:00, 11662.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score -> Median Noise Normalized Squared Correlation Percentage (LH and RH)\n",
      "LH subj 1 | Score:  48.39405012388089\n",
      "RH subj 1 | Score:  47.737441465482924\n"
     ]
    }
   ],
   "source": [
    "lh_fmri_val_pred, lh_fmri_test_pred, rh_fmri_val_pred, rh_fmri_test_pred = linear_regression(regression_type, \n",
    "                                                                                                features_train, \n",
    "                                                                                                features_val, \n",
    "                                                                                                features_test, \n",
    "                                                                                                lh_fmri_train, \n",
    "                                                                                                rh_fmri_train, \n",
    "                                                                                                save_predictions,\n",
    "                                                                                                args.subject_test_submission_dir,\n",
    "                                                                                                alpha_l,\n",
    "                                                                                                alpha_r,\n",
    "                                                                                                grid_search= False)\n",
    "\n",
    "noise_norm_corr_dict[f'lh_{subj}'], noise_norm_corr_dict[f'rh_{subj}'] = median_squared_noisenorm_correlation(lh_fmri_val_pred, \n",
    "                                                                                                                rh_fmri_val_pred,\n",
    "                                                                                                                lh_fmri_val,\n",
    "                                                                                                                rh_fmri_val,\n",
    "                                                                                                                args.data_dir,\n",
    "                                                                                                                args.ncsnr_dir,\n",
    "                                                                                                                args.images_trials_dir,\n",
    "                                                                                                                idxs_val)\n",
    "print(\"\\n Score -> Median Noise Normalized Squared Correlation Percentage (LH and RH)\")\n",
    "print(\"LH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'lh_{subj}'])*100)\n",
    "print(\"RH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'rh_{subj}'])*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m histogram(args\u001b[39m.\u001b[39;49mdata_dir, noise_norm_corr_dict[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlh_\u001b[39;49m\u001b[39m{\u001b[39;49;00msubj\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m      2\u001b[0m           noise_norm_corr_dict[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrh_\u001b[39;49m\u001b[39m{\u001b[39;49;00msubj\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m      3\u001b[0m           submission_name, \n\u001b[0;32m      4\u001b[0m           save \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Projects\\Thesis\\src\\visualize.py:91\u001b[0m, in \u001b[0;36mhistogram\u001b[1;34m(roi_path, lh_correlation, rh_correlation, title, save)\u001b[0m\n\u001b[0;32m     84\u001b[0m fig\u001b[39m.\u001b[39mupdate_layout(title_text\u001b[39m=\u001b[39mtitle, yaxis\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m[\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m]), yaxis_title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMedian Noise Normalized Encoding Accuracy\u001b[39m\u001b[39m\"\u001b[39m, xaxis_title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mROIs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m save \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m     \u001b[39m# if not osp.isdir(save):\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[39m#     os.makedirs(save)\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     to_save \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39;49mjoin(save, \u001b[39m\"\u001b[39;49m\u001b[39mhistogram_pearson_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\n\u001b[0;32m     92\u001b[0m         strftime(\u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m%\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m\"\u001b[39;49m)))\n\u001b[0;32m     94\u001b[0m     fig\u001b[39m.\u001b[39mwrite_html(to_save\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.html\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m     fig\u001b[39m.\u001b[39mwrite_image(to_save\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giorg\\miniconda3\\envs\\algonauts\\lib\\ntpath.py:78\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(path, \u001b[39m*\u001b[39mpaths):\n\u001b[1;32m---> 78\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mfspath(path)\n\u001b[0;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m     80\u001b[0m         sep \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not bool"
     ]
    }
   ],
   "source": [
    "histogram(args.data_dir, noise_norm_corr_dict[f'lh_{subj}'], \n",
    "          noise_norm_corr_dict[f'rh_{subj}'], \n",
    "          submission_name, \n",
    "          save = args.subject_images_submission_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(args.data_dir, noise_norm_corr_dict[f'lh_{subj}'], \n",
    "          noise_norm_corr_dict[f'rh_{subj}'], \n",
    "          submission_name, \n",
    "          save = args.subject_images_submission_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algonauts",
   "language": "python",
   "name": "algonauts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
