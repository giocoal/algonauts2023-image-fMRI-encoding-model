{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if GPU is available and if torch is using it ..\n",
      "\n",
      "\n",
      "Torch Cuda is available?\n",
      "True\n",
      "Torch Cuda device count is :\n",
      "1\n",
      "Torch Cuda current device is :\n",
      "0\n",
      "Torch Cuda device is :\n",
      "<torch.cuda.device object at 0x000002C7DFA576A0>\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "Pytorch version：\n",
      "1.13.0\n",
      "CUDA Version: \n",
      "11.6\n",
      "cuDNN version is :\n",
      "8302\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Packages import\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "from src.cuda_checker import cuda_torch_check, memory_checker\n",
    "\n",
    "### My modules import\n",
    "from src.data_loader import argObj, data_loaders_stimuli_fmri\n",
    "from src import image_preprocessing\n",
    "from src.feature_extraction import model_loader, fit_pca, pca_batch_calculator, extract_and_pca_features, extract_features_no_pca\n",
    "from src.encoding import linear_regression, compute_perason_numpy\n",
    "from src.evaluation_metrics import median_squared_noisenorm_correlation\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import pearsonr\n",
    "from src.visualize import histogram, box_plot\n",
    "\n",
    "### Cuda setup and check\n",
    "import torch\n",
    "# Select the device to run the model on\n",
    "device = 'cuda' #@param ['cpu', 'cuda'] {allow-input: true}\n",
    "# Check if cuda is available\n",
    "device = torch.device(device)\n",
    "cuda_torch_check()\n",
    "\n",
    "### Parameters definition\n",
    "train_percentage = 90 # X% of the training data will be used for training, (100-X)% for validation\n",
    "transform = image_preprocessing.imagenet_transform_alt\n",
    "\n",
    "batch_size = 64\n",
    "pca_component = 300\n",
    "min_pca_batch_size = pca_component + 200 # pca_component * 2\n",
    "\n",
    "compute_pca = True\n",
    "feature_model_type = \"alexnet\" #@param [\"alexnet\", \"vgg16\", \"vgg19_bn, \"\"efficientnetb2\", \"efficientnet_b5\", \"efficientnetb2lib\", \"ZFNet\", \"DINOv2\"]\n",
    "model_layer = \"features.12\"\n",
    "regression_type = \"ridge\" #@param [\"linear\", \"ridge\"]\n",
    "\n",
    "save = False\n",
    "\n",
    "alpha_l = None\n",
    "alpha_r = None\n",
    "grid_search = False\n",
    "\n",
    "subj = 1\n",
    "noise_norm_corr_dict = {}\n",
    "\n",
    "### Path definition\n",
    "if isinstance(model_layer, list):\n",
    "    model_layer_full = '+'.join(model_layer)\n",
    "else:\n",
    "    model_layer_full = model_layer\n",
    "submission_name = f'{feature_model_type}_{model_layer}-pca_{pca_component}-{regression_type}-alpha_{alpha_l}'\n",
    "\n",
    "# Data folder definition\n",
    "data_home_dir = '../Datasets/Biomedical'\n",
    "data_dir = '../Datasets/Biomedical/algonauts_2023_challenge_data'\n",
    "# Used to save the prediction of saved model\n",
    "parent_submission_dir = f'./files/submissions/{submission_name}'\n",
    "if not os.path.isdir(parent_submission_dir) and save:\n",
    "            os.makedirs(parent_submission_dir)\n",
    "images_submission_dir = f\"./files/submissions/imgs/{submission_name}\"\n",
    "ncsnr_dir = '../Datasets/Biomedical/algonauts_ncsnr'\n",
    "images_trials_dir = '../Datasets/Biomedical/algonauts_train_images_trials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alexnet_features.12-pca_300-ridge-alpha_None'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet_features.12-pca_300-ridge-alpha_None\n",
      "\n",
      "############################ Subject: 1 ############################ \n",
      "\n",
      "## Stimulus Images Loading: Info\n",
      "Total train images: 9841\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "Test stimulus images: 159\n",
      "\n",
      "\n",
      "## Loading feature extraction model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\giorg/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Feature extractor: alexnet, layer: features.12\n"
     ]
    }
   ],
   "source": [
    "print(submission_name + \"\\n\")\n",
    "print('############################ Subject: ' + str(subj) + ' ############################ \\n')\n",
    "# Definining paths to data and submission directories ##\n",
    "args = argObj(subj, data_home_dir, data_dir, parent_submission_dir, ncsnr_dir, images_trials_dir, save)\n",
    "# Obtain the indices of the training, validation and test data\n",
    "idxs_train, idxs_val, idxs_test, train_imgs_paths, test_imgs_paths = args.images_idx_splitter(train_percentage)\n",
    "\n",
    "# Defining the images data loaderds\n",
    "data_loaders = data_loaders_stimuli_fmri(idxs_train, \n",
    "                                            idxs_val, \n",
    "                                            idxs_test, \n",
    "                                            train_imgs_paths, \n",
    "                                            test_imgs_paths,\n",
    "                                            lh_fmri_path = args.lh_fmri,\n",
    "                                            rh_fmri_path = args.rh_fmri)\n",
    "\n",
    "train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader = data_loaders.images_dataloader(batch_size, transform)\n",
    "\n",
    "model, feature_extractor = model_loader(feature_model_type, model_layer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "## Calculating PCA batch size...\n",
      "Batches size: 64\n",
      "Total train instances: 8857\n",
      "PCA components: 300\n",
      "Minimum pca batch size: 500\n",
      "Number of stacked batches for pca: 10\n",
      "PCA batch size (batch_size * n_stacked_batches): 640\n",
      "Last pca batch size: 537\n",
      "## Fitting Incremental PCA (300 components) to training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [01:46<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comulative Explained variance ratio:  0.6437733876120811\n",
      "Number of components:  300\n",
      "## Extracting features from training, validation and test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [01:11<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital features number: 9216, final features number: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital features number: 9216, final features number: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital features number: 9216, final features number: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the PCA model\n",
    "if compute_pca:\n",
    "    # Fit the PCA model\n",
    "    pca_batch_size, n_stacked_batches = pca_batch_calculator(len(idxs_train),\n",
    "                                                            batch_size,\n",
    "                                                            min_pca_batch_size,\n",
    "                                                            pca_component)\n",
    "    \n",
    "    pca = fit_pca(feature_extractor,\n",
    "                    train_imgs_dataloader,\n",
    "                    pca_component,\n",
    "                    n_stacked_batches,\n",
    "                    pca_batch_size,\n",
    "                    device)\n",
    "    print(\"Comulative Explained variance ratio: \", sum(pca.explained_variance_ratio_))\n",
    "    print(\"Number of components: \", pca.n_components_)\n",
    "    \n",
    "    print('## Extracting features from training, validation and test data...')\n",
    "    features_train = extract_and_pca_features(feature_extractor, train_imgs_dataloader, pca, n_stacked_batches, device)\n",
    "    features_val = extract_and_pca_features(feature_extractor, val_imgs_dataloader, pca, n_stacked_batches, device)\n",
    "    features_test = extract_and_pca_features(feature_extractor, test_imgs_dataloader, pca, n_stacked_batches, device)\n",
    "    \n",
    "    # print(\"\\n\")\n",
    "    # print('## Checking and Freeing  GPU memory...')\n",
    "    # memory_checker()\n",
    "    model.to('cpu') # sposto sulla ram\n",
    "    feature_extractor.to('cpu') # sposto sulla ram\n",
    "    del model, feature_extractor, pca, train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader  # elimino dalla ram\n",
    "    torch.cuda.empty_cache() # elimino la chache vram\n",
    "    gc.collect() # elimino la cache ram\n",
    "    # memory_checker()\n",
    "else:\n",
    "    print('## Extracting features from training, validation and test data...')\n",
    "    features_train = extract_features_no_pca(feature_extractor, train_imgs_dataloader, device)\n",
    "    features_val = extract_features_no_pca(feature_extractor, val_imgs_dataloader, device)\n",
    "    features_test = extract_features_no_pca(feature_extractor, test_imgs_dataloader, device)\n",
    "    \n",
    "    model.to('cpu') # sposto sulla ram\n",
    "    feature_extractor.to('cpu') # sposto sulla ram\n",
    "    del model, feature_extractor, train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader  # elimino dalla ram\n",
    "    torch.cuda.empty_cache() # elimino la chache vram\n",
    "    gc.collect() # elimino la cache ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = data_loaders.fmri_splitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge/Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search (ridgeR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ## Fit Encoder and Predict...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LH fMRI number of vertices: (8857, 19004)\n",
      "RH fMRI number of vertices: (8857, 20544)\n"
     ]
    }
   ],
   "source": [
    "## Fit the linear model ##\n",
    "print('\\n ## Fit Encoder and Predict...')\n",
    "lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = data_loaders.fmri_splitter()\n",
    "print('LH fMRI number of vertices:', lh_fmri_train.shape)\n",
    "print('RH fMRI number of vertices:', rh_fmri_train.shape)\n",
    "# param_grid = {'alpha': [0.0001, 0.0002, 0.001, 0.01, 0.1, 1, 10, 100, 1e3, 5e3, 1e4, 2e4, 5e4, 1e5, 1e6]}\n",
    "\n",
    "param_grid = {'alpha': [1, 10, 100, 1e3, 5e3, 1e4, 2e4, 5e4, 1e5, 2e5, 5e5, 1e6]}\n",
    "#param_grid = {'alpha': [1e6, 2e6, 5e6, 1e7, 2e7, 5e7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Param: {'alpha': 100000.0}\n",
      "Best Score: 0.4171876543623486\n"
     ]
    }
   ],
   "source": [
    "grid_search_l = GridSearchCV(Ridge(), param_grid=param_grid, scoring=make_scorer(\n",
    "    lambda x, y: np.median(compute_perason_numpy(x, y))), cv=5, n_jobs=5, verbose=1)\n",
    "grid_search_l.fit(X=features_train, y=lh_fmri_train)\n",
    "print(\"Best Param: {}\".format(grid_search_l.best_params_))\n",
    "print(\"Best Score: {}\".format(grid_search_l.best_score_))\n",
    "alpha_l = grid_search_l.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_r = alpha_l = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000.0\n"
     ]
    }
   ],
   "source": [
    "print(alpha_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "grid_search_r = GridSearchCV(Ridge(), param_grid=param_grid, scoring=make_scorer(\n",
    "    lambda x, y: np.median(compute_perason_numpy(x, y))), cv=5, n_jobs=5, verbose=1)\n",
    "grid_search_r.fit(X=features_train, y=rh_fmri_train)\n",
    "print(\"Best Param: {}\".format(grid_search_r.best_params_))\n",
    "print(\"Best Score: {}\".format(grid_search_r.best_score_))\n",
    "alpha_r = grid_search_r.best_params_['alpha']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ridge regressions on the training data...\n",
      "Predicting fMRI data on the validation and test data...\n",
      "Computing the correlation between the predicted and actual fMRI data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:01<00:00, 13989.54it/s]\n",
      "100%|██████████| 20544/20544 [00:01<00:00, 14226.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score -> Median Noise Normalized Squared Correlation Percentage (LH and RH)\n",
      "LH subj 1 | Score:  44.3897836454705\n",
      "RH subj 1 | Score:  43.29265074582257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lh_fmri_val_pred, lh_fmri_test_pred, rh_fmri_val_pred, rh_fmri_test_pred = linear_regression(regression_type, \n",
    "                                                                                                features_train, \n",
    "                                                                                                features_val, \n",
    "                                                                                                features_test, \n",
    "                                                                                                lh_fmri_train, \n",
    "                                                                                                rh_fmri_train, \n",
    "                                                                                                save,\n",
    "                                                                                                args.subject_test_submission_dir,\n",
    "                                                                                                alpha_l,\n",
    "                                                                                                alpha_r,\n",
    "                                                                                                grid_search= False)\n",
    "\n",
    "noise_norm_corr_dict[f'lh_{subj}'], noise_norm_corr_dict[f'rh_{subj}'] = median_squared_noisenorm_correlation(lh_fmri_val_pred, \n",
    "                                                                                                                rh_fmri_val_pred,\n",
    "                                                                                                                lh_fmri_val,\n",
    "                                                                                                                rh_fmri_val,\n",
    "                                                                                                                args.data_dir,\n",
    "                                                                                                                args.ncsnr_dir,\n",
    "                                                                                                                args.images_trials_dir,\n",
    "                                                                                                                idxs_val)\n",
    "print(\"\\n Score -> Median Noise Normalized Squared Correlation Percentage (LH and RH)\")\n",
    "print(\"LH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'lh_{subj}'])*100)\n",
    "print(\"RH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'rh_{subj}'])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression with non-linear kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ## Fit Encoder and Predict...\n",
      "LH fMRI number of vertices: (8857, 19004)\n",
      "RH fMRI number of vertices: (8857, 20544)\n"
     ]
    }
   ],
   "source": [
    "print('\\n ## Fit Encoder and Predict...')\n",
    "lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = data_loaders.fmri_splitter()\n",
    "print('LH fMRI number of vertices:', lh_fmri_train.shape)\n",
    "print('RH fMRI number of vertices:', rh_fmri_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = MultiOutputRegressor(SVR(),n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'estimator__C': [0.1, 1, 10, 100], \n",
    "              'estimator__epsilon': [0.01, 0.1, 1, 10],  \n",
    "              'estimator__kernel': ['rbf', 'poly']}\n",
    "# 'gamma': [0.1, 1, 10, 100],\n",
    "# Crea un oggetto SVR\n",
    "\n",
    "grid_search_svr_l = GridSearchCV(svr, param_grid=param_grid, scoring=make_scorer(\n",
    "    lambda x, y: np.median(compute_perason_numpy(x, y))), cv=5, n_jobs=5, verbose=10)\n",
    "\n",
    "# Addestra il modello SVR utilizzando la griglia di ricerca degli iperparametri\n",
    "grid_search_svr_l.fit(X=features_train, y=lh_fmri_train)\n",
    "\n",
    "# Ottieni i migliori parametri trovati dalla griglia di ricerca\n",
    "best_params_svr_l = grid_search_svr_l.best_params_\n",
    "\n",
    "print(\"Best Param: {}\".format(best_params_svr_l))\n",
    "print(\"Best Score: {}\".format(grid_search_svr_l.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_svr_r = best_params_svr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_svr_l = SVR(C=best_params_svr_l['C'], epsilon=best_params_svr_l['epsilon'], gamma=\"auto\", kernel=best_params_svr_l['kernel'])\n",
    "reg_svr_l.fit(features_train, lh_fmri_train)\n",
    "\n",
    "reg_svr_r = SVR(C=best_params_svr_r['C'], epsilon=best_params_svr_r['epsilon'], gamma=\"auto\", kernel=best_params_svr_r['kernel'])\n",
    "reg_svr_r.fit(features_train, rh_fmri_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_svr_l = MultiOutputRegressor(SVR(gamma=\"auto\", kernel='rbf'),n_jobs=-1)\n",
    "reg_svr_l.fit(features_train, lh_fmri_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_svr_r = MultiOutputRegressor(SVR(gamma=\"auto\", kernel='rbf'),n_jobs=-1)\n",
    "reg_svr_r.fit(features_train, rh_fmri_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg_svr_l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lh_fmri_val_pred \u001b[39m=\u001b[39m reg_svr_l\u001b[39m.\u001b[39mpredict(features_val)\n\u001b[0;32m      2\u001b[0m rh_fmri_val_pred \u001b[39m=\u001b[39m reg_svr_l\u001b[39m.\u001b[39mpredict(features_val)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reg_svr_l' is not defined"
     ]
    }
   ],
   "source": [
    "lh_fmri_val_pred = reg_svr_l.predict(features_val)\n",
    "rh_fmri_val_pred = reg_svr_l.predict(features_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_norm_corr_dict[f'lh_{subj}'], noise_norm_corr_dict[f'rh_{subj}'] = median_squared_noisenorm_correlation(lh_fmri_val_pred, \n",
    "                                                                                                                rh_fmri_val_pred,\n",
    "                                                                                                                lh_fmri_val,\n",
    "                                                                                                                rh_fmri_val,\n",
    "                                                                                                                args.data_dir,\n",
    "                                                                                                                args.ncsnr_dir,\n",
    "                                                                                                                args.images_trials_dir,\n",
    "                                                                                                                idxs_val)\n",
    "print(\"\\n Score -> Median Noise Normalized Squared Correlation Percentage (LH and RH)\")\n",
    "print(\"LH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'lh_{subj}'])*100)\n",
    "print(\"RH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'rh_{subj}'])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ## Fit Encoder and Predict...\n",
      "LH fMRI number of vertices: (8857, 19004)\n",
      "RH fMRI number of vertices: (8857, 20544)\n"
     ]
    }
   ],
   "source": [
    "print('\\n ## Fit Encoder and Predict...')\n",
    "lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = data_loaders.fmri_splitter()\n",
    "print('LH fMRI number of vertices:', lh_fmri_train.shape)\n",
    "print('RH fMRI number of vertices:', rh_fmri_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {'max_depth': [None, 5, 10, 15],\n",
    "#               'min_samples_split': [2, 5, 10],\n",
    "#               'min_samples_leaf': [1, 2, 4],\n",
    "#               'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "param_grid = {'max_depth': [None, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "grid_search_tree_l = GridSearchCV(tree_reg, param_grid=param_grid, scoring=make_scorer(\n",
    "    lambda x, y: np.median(compute_perason_numpy(x, y))), cv=5, n_jobs=5, verbose=10)\n",
    "\n",
    "grid_search_tree_l.fit(X=features_train, y=lh_fmri_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni i migliori parametri trovati dalla griglia di ricerca\n",
    "best_params_tree_l = grid_search_tree_l.best_params_\n",
    "\n",
    "print(\"Best Param: {}\".format(best_params_tree_l))\n",
    "print(\"Best Score: {}\".format(grid_search_tree_l.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_tree_r = best_params_tree_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_l = DecisionTreeRegressor(max_depth=best_params_tree_l['max_depth'],\n",
    "                                 min_samples_split=best_params_tree_l['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params_tree_l['min_samples_leaf'],\n",
    "                                 max_features=best_params_tree_l['max_features'])\n",
    "reg_tree_l.fit(features_train, lh_fmri_train)\n",
    "\n",
    "reg_tree_r = DecisionTreeRegressor(max_depth=best_params_tree_r['max_depth'],\n",
    "                                 min_samples_split=best_params_tree_r['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params_tree_r['min_samples_leaf'],\n",
    "                                 max_features=best_params_tree_r['max_features'])\n",
    "reg_tree_r.fit(features_train, lh_fmri_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No CV fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_svr_l = DecisionTreeRegressor(criterion = \"squared_error\", max_depth=5, max_features = None)\n",
    "reg_svr_l.fit(features_train, lh_fmri_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\miniconda3\\envs\\algonauts_test\\lib\\site-packages\\sklearn\\tree\\_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reg_svr_r = DecisionTreeRegressor(max_features = \"auto\")\n",
    "reg_svr_r.fit(features_train, rh_fmri_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_svr_r = reg_svr_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_fmri_val_pred = reg_svr_l.predict(features_val)\n",
    "rh_fmri_val_pred = reg_svr_l.predict(features_val)\n",
    "rh_fmri_val_pred = rh_fmri_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the correlation between the predicted and actual fMRI data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:01<00:00, 14119.53it/s]\n",
      "100%|██████████| 20544/20544 [00:00<00:00, 22544.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score -> Median Noise Normalized Squared Correlation Percentage (LH and RH)\n",
      "LH subj 1 | Score:  16.77595593341632\n",
      "RH subj 1 | Score:  100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "noise_norm_corr_dict[f'lh_{subj}'], noise_norm_corr_dict[f'rh_{subj}'] = median_squared_noisenorm_correlation(lh_fmri_val_pred, \n",
    "                                                                                                                rh_fmri_val_pred,\n",
    "                                                                                                                lh_fmri_val,\n",
    "                                                                                                                rh_fmri_val,\n",
    "                                                                                                                args.data_dir,\n",
    "                                                                                                                args.ncsnr_dir,\n",
    "                                                                                                                args.images_trials_dir,\n",
    "                                                                                                                idxs_val)\n",
    "print(\"\\n Score -> Median Noise Normalized Squared Correlation Percentage (LH and RH)\")\n",
    "print(\"LH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'lh_{subj}'])*100)\n",
    "print(\"RH subj\",subj,\"| Score: \",np.median(noise_norm_corr_dict[f'rh_{subj}'])*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m histogram(args\u001b[39m.\u001b[39;49mdata_dir, noise_norm_corr_dict[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlh_\u001b[39;49m\u001b[39m{\u001b[39;49;00msubj\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m      2\u001b[0m           noise_norm_corr_dict[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrh_\u001b[39;49m\u001b[39m{\u001b[39;49;00msubj\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m      3\u001b[0m           submission_name, \n\u001b[0;32m      4\u001b[0m           save \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Projects\\Thesis\\src\\visualize.py:91\u001b[0m, in \u001b[0;36mhistogram\u001b[1;34m(roi_path, lh_correlation, rh_correlation, title, save)\u001b[0m\n\u001b[0;32m     84\u001b[0m fig\u001b[39m.\u001b[39mupdate_layout(title_text\u001b[39m=\u001b[39mtitle, yaxis\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m[\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m]), yaxis_title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMedian Noise Normalized Encoding Accuracy\u001b[39m\u001b[39m\"\u001b[39m, xaxis_title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mROIs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m save \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m     \u001b[39m# if not osp.isdir(save):\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[39m#     os.makedirs(save)\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     to_save \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39;49mjoin(save, \u001b[39m\"\u001b[39;49m\u001b[39mhistogram_pearson_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\n\u001b[0;32m     92\u001b[0m         strftime(\u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m%\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m\"\u001b[39;49m)))\n\u001b[0;32m     94\u001b[0m     fig\u001b[39m.\u001b[39mwrite_html(to_save\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.html\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m     fig\u001b[39m.\u001b[39mwrite_image(to_save\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giorg\\miniconda3\\envs\\algonauts\\lib\\ntpath.py:78\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(path, \u001b[39m*\u001b[39mpaths):\n\u001b[1;32m---> 78\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mfspath(path)\n\u001b[0;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m     80\u001b[0m         sep \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not bool"
     ]
    }
   ],
   "source": [
    "histogram(args.data_dir, noise_norm_corr_dict[f'lh_{subj}'], \n",
    "          noise_norm_corr_dict[f'rh_{subj}'], \n",
    "          submission_name, \n",
    "          save = args.subject_images_submission_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(args.data_dir, noise_norm_corr_dict[f'lh_{subj}'], \n",
    "          noise_norm_corr_dict[f'rh_{subj}'], \n",
    "          submission_name, \n",
    "          save = args.subject_images_submission_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algonauts_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
